<!Doctype html>
<html lang="en">
    <head>
        <title>EVREAL: Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction</title>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="author" content="Burak Ercan">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="icon" type="image/png" href="data/bunny.png"/>

        <link rel="stylesheet" type="text/css" href="style_project_page.css?cache=7754391418498779889">
        <link href="https://fonts.googleapis.com/css?family=Arvo|Roboto&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
        <link rel="stylesheet" href="https://unpkg.com/@glidejs/glide/dist/css/glide.core.min.css">
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="https://unpkg.com/@glidejs/glide"></script>
        <style type="text/css">
            .side-text {
                width:60%;
                display:inline-block;
                vertical-align:top;
            }
            .side-image {
                width: 38%;
                display: inline-block;
                vertical-align: top;
            }
            .controls {
                margin-bottom: 10px;
            }
            .left-controls {
                display: inline-block;
                vertical-align: top;
                width: 80%;
            }
            .right-controls {
                display: inline-block;
                vertical-align: top;
                width: 19%;
                text-align: right;
            }
            .render_window {
                display: inline-block;
                vertical-align: middle;
                box-shadow: 1px 0px 5px black;
                margin-right: 10px;
                margin-bottom: 10px;
                width: calc(33% - 10px);
            }
            .progress {
                background: #666;
                position: relative;
                height: 5px;
                margin-bottom: -5px;
                display: none;
            }
            .glide__slide:hover {cursor: grab;}
            .glide__slide:active {cursor: grabbing;}
            .glide__slide img {width: 90%;}
            .glide__bullets {
                text-align: center;
            }
            .glide__bullet--active {
                color: #aaa; 
            }

            @media (max-width: 400px) {
                .render_window {
                    display: block;
                    width: 90%;
                    margin: 10px auto;
                }
            }
            @media (max-width: 700px) {
                .side-image {
                    display: block;
                    width: 80%;
                    margin: 10px auto;
                }
                .side-text {
                    display: block;
                    width: 100%;
                }
            }
        </style>
    </head>
    <body>
        <div class="section">
            <h1 class="project-title">
                EVREAL: Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction
            </h1>
            <div class="authors">
                <a href=https://ercanburak.github.io/>
                    Burak Ercan <sup>1,2</sup>
                </a>
                <a href=https://github.com/ekeronur/>
                    Onur Eker <sup>1,2</sup>
                </a>
                <a href=https://aykuterdem.github.io/>
                    Aykut Erdem <sup>3,4</sup>
                </a>
                <a href=https://web.cs.hacettepe.edu.tr/~erkut/>
                    Erkut Erdem <sup>1,4</sup>
                </a>
            </div>

            <div class="affiliations">           
                <span><sup>1</sup> <a href=https://cs.hacettepe.edu.tr> Hacettepe University, Computer Engineering Department</a>   </span>
                <span><sup>2</sup> <a href=https://www.havelsan.com.tr/en> HAVELSAN Inc.</a></span> <br/>
                <span><sup>3</sup> <a href=https://cs.ku.edu.tr> Koç University, Computer Engineering Department</a></span>
                <span><sup>4</sup> <a href=https://ai.ku.edu.tr> Koç University, KUIS AI Center</a></span> <br/>
            </div>

            <div class="project-conference">
                <a href=https://tub-rip.github.io/eventvision2023/>CVPR 2023 Workshop on Event-based Vision</a>                
            </div>

            <div class="project-icons">
                <a href="https://arxiv.org/abs/2305.00434/">
                    <i class="fa fa-file"></i> <br/>
                    Paper
                </a>
                <a href="https://github.com/ercanburak/EVREAL">
                    <i class="fa fa-github"></i> <br/>
                    Code
                </a>
            </div>

            <div class="teaser-image">
                <p class="content">Here we present <strong>EVREAL - Event-based Video Reconstruction Evaluation and Analysis Library. </strong> Our open-source framework offers a unified evaluation pipeline to comprehensively benchmark PyTorch based <strong>pre-trained neural networks</strong> for <strong>event-based video reconstruction</strong>, and a result analysis tool to <strong>visualize and compare</strong> reconstructions and their scores. <br/> </p>
                <img src="projects/evreal/diagram.png" style="width:100%;">
                <p class="content"> <br/>  We use a large set of real-world test sequences and various full-reference and no-reference image quality metrics to perform qualitative and quantitative analysis under diverse conditions, including challenging scenarios such as rapid motion, low light, and high dynamic range. Furthermore, we conduct additional experiments to assess the performance of each method under variable conditions and analyze their robustness to these varying settings, including event rate, event tensor sparsity, reconstruction rate, and temporal irregularity. Moreover, we evaluate the quality of video reconstruction for each method by analyzing its performance in downstream tasks, including camera calibration, image classification, and object detection. Overall, we believe that EVREAL will contribute to the development of more effective and robust event-based video reconstruction methods. </p>
            </div>

            <div class="content">
                <div class="section-title"> Result Analysis Tool </div>
                <iframe
                    src="https://ercanburak-evreal.hf.space/?header=false"
                    frameborder="0"
                    width="100%"
                    height="650"
                ></iframe>
            </div>
            <div class="section">
                <h4 class="title">
                    BibTeX
                </h4>
                <p class="content">
                    <pre><code>@inproceedings{ercan2023evreal,
title={{EVREAL}: Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction},
author={Ercan, Burak and Eker, Onur and Erdem, Aykut and Erdem, Erkut},
booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month={June},
year={2023},
pages={3942-3951}}</code></pre>
                </p>
            </div>
            <div class="section-title"> Acknowledgements </div>
            <div class="content">
                This work was supported in part by KUIS AI Center Research Award, TUBITAK-1001 Program Award No. 121E454, and BAGEP 2021 Award of the Science Academy to A. Erdem.
            </div>
        </div>
    </body>
</html>
