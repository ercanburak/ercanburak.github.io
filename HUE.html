<!Doctype html>
<html lang="en">
    <head>
        <title>HUE Dataset: High-Resolution Event and Frame Sequences for Low-Light Vision</title>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="author" content="Burak Ercan">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="icon" type="image/png" href="data/bunny.png"/>

        <link rel="stylesheet" type="text/css" href="style_project_page.css?cache=7754391418498779889">
        <link href="https://fonts.googleapis.com/css?family=Arvo|Roboto&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
        <link rel="stylesheet" href="https://unpkg.com/@glidejs/glide/dist/css/glide.core.min.css">
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="https://unpkg.com/@glidejs/glide"></script>
        <style>
            .image-container {
	            display: flex;
	            flex-wrap: nowrap;
	            justify-content: center;
	            align-items: center;
                object-fit: scale-down;
            }
            .image-container img {
	            width: 200px;
	            height: 180px;
	            margin: 5px;
	            flex: 2;
            }
            iframe {
                display: block;
                text-align: center;
                border-style:none;
            }
        </style>


        <style type="text/css">
            .side-text {
                width:60%;
                display:inline-block;
                vertical-align:top;
            }
            .side-image {
                width: 38%;
                display: inline-block;
                vertical-align: top;
            }
            .controls {
                margin-bottom: 10px;
            }
            .left-controls {
                display: inline-block;
                vertical-align: top;
                width: 80%;
            }
            .right-controls {
                display: inline-block;
                vertical-align: top;
                width: 19%;
                text-align: right;
            }
            .render_window {
                display: inline-block;
                vertical-align: middle;
                box-shadow: 1px 0px 5px black;
                margin-right: 10px;
                margin-bottom: 10px;
                width: calc(33% - 10px);
            }
            .progress {
                background: #666;
                position: relative;
                height: 5px;
                margin-bottom: -5px;
                display: none;
            }
            .glide__slide:hover {cursor: grab;}
            .glide__slide:active {cursor: grabbing;}
            .glide__slide img {width: 90%;}
            .glide__bullets {
                text-align: center;
            }
            .glide__bullet--active {
                color: #aaa; 
            }

            body {
                font-size: 12pt;
                hyphens: none;
                -moz-hyphens: none;
                -webkit-hyphens: none;
            }
            .section .content, .teaser-image .content {
                font-size: 13pt;
                line-height: 1.6em;
            }
            h1.project-title {
                font-family: 'Arvo', serif;
                font-size: 28px;
            }
            .authors a {
                font-size: 22px;
                font-family: 'Roboto', sans-serif;
            }
            .affiliations {
                font-size: 17px;
                font-family: 'Roboto', sans-serif;
            }
            .project-conference {
                font-size: 20px;
                font-family: 'Roboto', sans-serif;
            }
            .project-icons a {
                font-size: 13px;
                font-family: 'Roboto', sans-serif;
            }
            .section-title, .section > .title, h4.title {
                font-family: 'Arvo', serif;
            }

            .format-table {
                width: 100%;
                border-collapse: collapse;
                margin: 15px 0;
                font-size: 0.95em;
            }
            .format-table th, .format-table td {
                text-align: left;
                padding: 8px 12px;
                border-bottom: 1px solid #ddd;
            }
            .format-table th {
                background: #f0f0f0;
                font-family: 'Arvo', serif;
                font-size: 1em;
            }
            .format-table td:first-child {
                white-space: nowrap;
                font-size: 0.9em;
            }
            .format-table code {
                background: #f0f0f0;
                padding: 1px 4px;
                border-radius: 3px;
                font-size: 0.92em;
            }

            .dataset-category {
                display: flex;
                align-items: center;
                margin-bottom: 20px;
                padding: 15px;
                background: #f9f9f9;
                border-radius: 8px;
                border: 1px solid #eee;
            }
            .category-video {
                flex: 0 0 60%;
                margin-right: 20px;
            }
            .category-video video {
                width: 100%;
                border-radius: 6px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.15);
            }
            .category-info {
                flex: 1;
                word-break: keep-all;
                overflow-wrap: normal;
            }
            .category-info h5 {
                margin: 0 0 4px 0;
                font-size: 1.2em;
                font-family: 'Arvo', serif;
            }
            .category-stats {
                font-size: 0.9em;
                color: #666;
                margin-bottom: 8px;
            }
            .category-info p {
                margin: 0 0 10px 0;
                font-size: 0.95em;
            }
            .category-download {
                font-size: 0.9em;
            }
            .category-download a {
                margin-right: 4px;
            }

            @media (max-width: 600px) {
                .dataset-category {
                    flex-direction: column;
                }
                .category-video {
                    flex: none;
                    width: 100%;
                    margin-right: 0;
                    margin-bottom: 12px;
                }
            }

            @media (max-width: 400px) {
                .render_window {
                    display: block;
                    width: 90%;
                    margin: 10px auto;
                }
            }
            @media (max-width: 700px) {
                .side-image {
                    display: block;
                    width: 80%;
                    margin: 10px auto;
                }
                .side-text {
                    display: block;
                    width: 100%;
                }
            }
        </style>
    </head>
    <body>
        <div class="section">
            <h1 class="project-title">
                HUE Dataset: High-Resolution Event and Frame Sequences for Low-Light Vision
            </h1>
            <div class="authors">
                <a href=https://ercanburak.github.io/>
                    Burak Ercan <sup>1</sup>
                </a>
                <a href=https://github.com/ekeronur/>
                    Onur Eker <sup>1,2</sup>
                </a>
                <a href=https://aykuterdem.github.io/>
                    Aykut Erdem <sup>3,4</sup>
                </a>
                <a href=https://web.cs.hacettepe.edu.tr/~erkut/>
                    Erkut Erdem <sup>1</sup>
                </a>
            </div>

            <div class="affiliations">           
                <span><sup>1</sup> <a href=https://cs.hacettepe.edu.tr> Hacettepe University, Computer Engineering Department</a></span> 
                <span><sup>2</sup> <a href=https://www.havelsan.com.tr/en> HAVELSAN Inc.</a></span> <br/>
                <span><sup>3</sup> <a href=https://cs.ku.edu.tr> Koç University, Computer Engineering Department</a></span>
                <span><sup>4</sup> <a href=https://ai.ku.edu.tr> Koç University, KUIS AI Center</a></span> <br/>
            </div>

            <div class="project-conference">
                <a href=https://sites.google.com/view/nevi2024>ECCV Workshop on Neuromorphic Vision, 2024</a>
            </div>

            <div class="project-icons">
                <a href="https://arxiv.org/abs/2410.19164">
                    <i class="fa fa-file"></i> <br/>
                    Paper
                </a>
                <a href="projects/HUE/supp.pdf">
                    <i class="fa fa-file-text"></i> <br/>
                    Supplementary
                </a>
            </div>

            <div class="teaser-image">
                <p class="content">Here we present <strong>HUE (Hacettepe University Event) Dataset</strong>, a comprehensive collection of <strong>high-resolution event and frame sequences</strong> captured in diverse and challenging <strong>low-light conditions</strong>. Our dataset offers <strong>106</strong> sequences across <strong>6</strong> categories, recorded using a hybrid RGB and event camera setup with events at 1280&times;720 and frames at 1456&times;1088 resolution. The sequences feature both static and dynamic scenes captured in indoor and outdoor environments, at various times of day, with illuminance levels ranging from 0 to 24 lux. Dataset parts are hosted on Zenodo, with download links below.</p>
            </div>

            <div class="content">
                <div class="dataset-category">
                    <div class="category-video">
                        <video autoplay loop muted playsinline>
                            <source src="projects/HUE/videos/indoor.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="category-info">
                        <h5>Indoor</h5>
                        <div class="category-stats">23 sequences &middot; 6 mins &middot; 0–3 lux</div>
                        <p>Indoor environments dimly lit via natural or artificial light sources.</p>
                        <div class="category-download">
                            <i class="fa fa-download"></i> Download:
                            <a href="https://zenodo.org/records/13850606">Part 1,</a>
                            <a href="https://zenodo.org/records/13883010">Part 2,</a>
                            <a href="https://zenodo.org/records/13883013">Part 3</a>
                        </div>
                    </div>
                </div>

                <div class="dataset-category">
                    <div class="category-video">
                        <video autoplay loop muted playsinline>
                            <source src="projects/HUE/videos/city.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="category-info">
                        <h5>City</h5>
                        <div class="category-stats">11 sequences &middot; 4 mins &middot; 0–14 lux</div>
                        <p>Capturing cityscapes through the window of a mid-rise building.</p>
                        <div class="category-download">
                            <i class="fa fa-download"></i> Download:
                            <a href="https://zenodo.org/records/13850671">Part 1,</a>
                            <a href="https://zenodo.org/records/13882992">Part 2</a>
                        </div>
                    </div>
                </div>

                <div class="dataset-category">
                    <div class="category-video">
                        <video autoplay loop muted playsinline>
                            <source src="projects/HUE/videos/twilight.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="category-info">
                        <h5>Twilight</h5>
                        <div class="category-stats">23 sequences &middot; 10 mins &middot; 0–24 lux</div>
                        <p>Outdoors during twilight, featuring natural and urban elements.</p>
                        <div class="category-download">
                            <i class="fa fa-download"></i> Download:
                            <a href="https://zenodo.org/records/13850716">Part 1,</a>
                            <a href="https://zenodo.org/records/13883017">Part 2,</a>
                            <a href="https://zenodo.org/records/13883020">Part 3,</a>
                            <a href="https://zenodo.org/records/13883029">Part 4</a>
                        </div>
                    </div>
                </div>

                <div class="dataset-category">
                    <div class="category-video">
                        <video autoplay loop muted playsinline>
                            <source src="projects/HUE/videos/night.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="category-info">
                        <h5>Night</h5>
                        <div class="category-stats">16 sequences &middot; 3 mins &middot; ~0 lux</div>
                        <p>Taken in urban environments during night, with moving people, cars, etc.</p>
                        <div class="category-download">
                            <i class="fa fa-download"></i> Download:
                            <a href="https://zenodo.org/records/13850750">HUE-Night</a>
                        </div>
                    </div>
                </div>

                <div class="dataset-category">
                    <div class="category-video">
                        <video autoplay loop muted playsinline>
                            <source src="projects/HUE/videos/driving.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="category-info">
                        <h5>Driving</h5>
                        <div class="category-stats">16 sequences &middot; 6 mins &middot; ~0 lux</div>
                        <p>From the windshield of a car driving around the city in twilight and night.</p>
                        <div class="category-download">
                            <i class="fa fa-download"></i> Download:
                            <a href="https://zenodo.org/records/13850768">Part 1,</a>
                            <a href="https://zenodo.org/records/13883000">Part 2</a>
                        </div>
                    </div>
                </div>

                <div class="dataset-category">
                    <div class="category-video">
                        <video autoplay loop muted playsinline>
                            <source src="projects/HUE/videos/controlled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="category-info">
                        <h5>Controlled</h5>
                        <div class="category-stats">17 sequences &middot; 2 mins &middot; 0–2 lux</div>
                        <p>Same scene captured under varying lighting levels and camera settings.</p>
                        <div class="category-download">
                            <i class="fa fa-download"></i> Download:
                            <a href="https://zenodo.org/records/13850789">HUE-Controlled</a>
                        </div>
                    </div>
                </div>

                <p style="margin-top: 10px;">
                    <i class="fa fa-download"></i> <a href="https://drive.google.com/drive/folders/1aT6CIqs58lUDsxg0wMFtcHlUgq47AAkz?usp=sharing">Additional calibration sequences</a> (flickering chessboard patterns for estimating intrinsic and extrinsic camera parameters)
                </p>

            </div>

            <div class="section-title"> Dataset Format </div>
            <div class="content">
                <p>
                    The events in the HUE dataset are stored in a numpy memmap format, similar to that of the <a href="https://github.com/TimoStoff/event_utils/">event_utils</a> library, and compatible with <a href="https://github.com/ercanburak/EVREAL/">EVREAL</a>.
                    Each sequence folder contains the following files:
                </p>
                <table class="format-table">
                    <thead>
                        <tr>
                            <th>File</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>events_p.npy</code></td>
                            <td>Event polarities.</td>
                        </tr>
                        <tr>
                            <td><code>events_ts.npy</code></td>
                            <td>Event timestamps in seconds.</td>
                        </tr>
                        <tr>
                            <td><code>events_xy.npy</code></td>
                            <td>Event (x, y) coordinates.</td>
                        </tr>
                        <tr>
                            <td><code>images_ts.npy</code></td>
                            <td>Image timestamps (midpoint of exposure).</td>
                        </tr>
                        <tr>
                            <td><code>images_exp_start_ts.npy</code></td>
                            <td>Image exposure start timestamps.</td>
                        </tr>
                        <tr>
                            <td><code>images_exp_end_ts.npy</code></td>
                            <td>Image exposure end timestamps.</td>
                        </tr>
                        <tr>
                            <td><code>image_event_indices.npy</code></td>
                            <td>For each image frame, the index of the last event at or before the image timestamp. Useful for aligning events with frames.</td>
                        </tr>
                        <tr>
                            <td><code>png_images/</code></td>
                            <td>8-bit 3-channel RGB images (1456&times;1088) captured by the frame camera, saved as PNG files (<code>rgb_00000.png</code>, <code>rgb_00001.png</code>, ...).</td>
                        </tr>
                        <tr>
                            <td><code>lux_values.txt</code></td>
                            <td>Light level (in lux) measured on the event sensor, recorded with each frame. One value per line, one per frame.</td>
                        </tr>
                        <tr>
                            <td><code>metadata.json</code></td>
                            <td>Sequence metadata, including event sensor resolution (<code>{"sensor_resolution": [720, 1280]}</code>).</td>
                        </tr>
                        <tr>
                            <td><code>event_camera_params.json</code></td>
                            <td>Event camera parameters captured via Prophesee SDK (sensor info, biases, firmware version, etc.).</td>
                        </tr>
                        <tr>
                            <td><code>frame_camera_params.xml</code></td>
                            <td>Frame camera settings captured via Allied Vision Vimba SDK (exposure, gain, frame rate, etc.).</td>
                        </tr>
                    </tbody>
                </table>
                <p>
                    All timestamps are in seconds, starting from 0.
                </p>
            </div>

            <div class="section">
                <h4 class="title">
                    BibTeX
                </h4>
                <p class="content">
                    <pre><code>@inproceedings{ercan2025hue,
title={{HUE} Dataset: High-Resolution Event and Frame Sequences for Low-Light Vision},
author={Ercan, Burak and Eker, Onur and Erdem, Aykut and Erdem, Erkut},
booktitle={Computer Vision -- ECCV 2024 Workshops},
year={2025},
pages={174-191}}</code></pre>
                </p>
            </div>
            <div class="section-title"> Acknowledgements </div>
            <div class="content">
                This work was supported by TUBITAK-1001 Program Award No. 121E454.
            </div>

    </body>
</html>
