<!Doctype html>
<html lang="en">
    <head>
        <title>HUE Dataset: High-Resolution Event and Frame Sequences for Low-Light Vision</title>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="author" content="Burak Ercan">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="icon" type="image/png" href="data/bunny.png"/>

        <link rel="stylesheet" type="text/css" href="style_project_page.css?cache=7754391418498779889">
        <link href="https://fonts.googleapis.com/css?family=Arvo|Roboto&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
        <link rel="stylesheet" href="https://unpkg.com/@glidejs/glide/dist/css/glide.core.min.css">
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="https://unpkg.com/@glidejs/glide"></script>
        <style>
            .image-container {
	            display: flex;
	            flex-wrap: nowrap;
	            justify-content: center;
	            align-items: center;
                object-fit: scale-down;
            }
            .image-container img {
	            width: 200px;
	            height: 180px;
	            margin: 5px;
	            flex: 2;
            }
            iframe {
                display: block;
                text-align: center;
                border-style:none;
            }
        </style>


        <style type="text/css">
            .side-text {
                width:60%;
                display:inline-block;
                vertical-align:top;
            }
            .side-image {
                width: 38%;
                display: inline-block;
                vertical-align: top;
            }
            .controls {
                margin-bottom: 10px;
            }
            .left-controls {
                display: inline-block;
                vertical-align: top;
                width: 80%;
            }
            .right-controls {
                display: inline-block;
                vertical-align: top;
                width: 19%;
                text-align: right;
            }
            .render_window {
                display: inline-block;
                vertical-align: middle;
                box-shadow: 1px 0px 5px black;
                margin-right: 10px;
                margin-bottom: 10px;
                width: calc(33% - 10px);
            }
            .progress {
                background: #666;
                position: relative;
                height: 5px;
                margin-bottom: -5px;
                display: none;
            }
            .glide__slide:hover {cursor: grab;}
            .glide__slide:active {cursor: grabbing;}
            .glide__slide img {width: 90%;}
            .glide__bullets {
                text-align: center;
            }
            .glide__bullet--active {
                color: #aaa; 
            }

            @media (max-width: 400px) {
                .render_window {
                    display: block;
                    width: 90%;
                    margin: 10px auto;
                }
            }
            @media (max-width: 700px) {
                .side-image {
                    display: block;
                    width: 80%;
                    margin: 10px auto;
                }
                .side-text {
                    display: block;
                    width: 100%;
                }
            }
        </style>
    </head>
    <body>
        <div class="section">
            <h1 class="project-title">
                HUE Dataset: High-Resolution Event and Frame Sequences for Low-Light Vision
            </h1>
            <div class="authors">
                <a href=https://ercanburak.github.io/>
                    Burak Ercan <sup>1</sup>
                </a>
                <a href=https://github.com/ekeronur/>
                    Onur Eker <sup>1,2</sup>
                </a>
                <a href=https://aykuterdem.github.io/>
                    Aykut Erdem <sup>3,4</sup>
                </a>
                <a href=https://web.cs.hacettepe.edu.tr/~erkut/>
                    Erkut Erdem <sup>1</sup>
                </a>
            </div>

            <div class="affiliations">           
                <span><sup>1</sup> <a href=https://cs.hacettepe.edu.tr> Hacettepe University, Computer Engineering Department</a></span> 
                <span><sup>2</sup> <a href=https://www.havelsan.com.tr/en> HAVELSAN Inc.</a></span> <br/>
                <span><sup>3</sup> <a href=https://cs.ku.edu.tr> Koç University, Computer Engineering Department</a></span>
                <span><sup>4</sup> <a href=https://ai.ku.edu.tr> Koç University, KUIS AI Center</a></span> <br/>
            </div>

            <div class="project-conference">
                <a href=https://sites.google.com/view/nevi2024>ECCV Workshop on Neuromorphic Vision, 2024</a>                
            </div>

            <div class="content">
                <p>
                    Low-light environments pose significant challenges for image enhancement methods. To address these challenges, in this work, we introduce the HUE dataset, a comprehensive collection of high-resolution event and frame sequences captured in diverse and challenging low-light conditions. Our dataset includes 106 sequences, encompassing indoor, cityscape, twilight, night, driving, and controlled scenarios, each carefully recorded to address various illumination levels and dynamic ranges. Utilizing a hybrid RGB and event camera setup. we collect a dataset that combines high-resolution event data with complementary frame data. We employ both qualitative and quantitative evaluations using no-reference metrics to assess state-of-the-art low-light enhancement and event-based image reconstruction methods. Additionally, we evaluate these methods on a downstream object detection task. Our findings reveal that while event-based methods perform well in specific metrics, they may produce false positives in practical applications. This dataset and our comprehensive analysis provide valuable insights for future research in low-light vision and hybrid camera systems. 
                </p>
            </div>

            <div class="content">
                <p>
                    Dataset will be published soon.
                </p>
            </div>

    </body>
</html>
